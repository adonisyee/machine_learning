{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I ran extractFrames.sh to use ffmpeg on my videos and extract \n",
    "all the frames. Mkdir wasn't working for me in the script for some \n",
    "reason so instead I removed that line, made the directories manually, \n",
    "and then ran it normally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Output of checkData.py:\n",
    "\n",
    "Running data check script on adonisyee.zip\n",
    "\n",
    "Checking that the compressed file has .zip extension......\n",
    "\n",
    "Passed!\n",
    "\n",
    "Unzipping adonisyee.zip\n",
    "\n",
    "Archive:  adonisyee.zip\n",
    "\n",
    "   creating: adonisyee/\n",
    "   \n",
    "  inflating: adonisyee/.DS_Store     \n",
    "  \n",
    "   creating: adonisyee/labels/\n",
    "   \n",
    "  inflating: adonisyee/labels/lunge_adonisyee.json \n",
    "  \n",
    "replace __MACOSX/adonisyee/labels/._lunge_adonisyee.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
    "\n",
    "  inflating: __MACOSX/adonisyee/labels/._lunge_adonisyee.json  \n",
    "  \n",
    "  inflating: adonisyee/labels/.DS_Store  \n",
    "  \n",
    "  inflating: adonisyee/labels/squat_adonisyee.json  \n",
    "  \n",
    "replace __MACOSX/adonisyee/labels/._squat_adonisyee.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
    "\n",
    "  inflating: __MACOSX/adonisyee/labels/._squat_adonisyee.json  \n",
    "  \n",
    "  inflating: adonisyee/labels/inline_adonisyee.json  \n",
    "  \n",
    "  inflating: __MACOSX/adonisyee/labels/._inline_adonisyee.json  \n",
    "  \n",
    "  inflating: adonisyee/labels/hamstrings_adonisyee.json  \n",
    "  \n",
    "  inflating: __MACOSX/adonisyee/labels/._hamstrings_adonisyee.json\n",
    "  \n",
    "  inflating: adonisyee/labels/stretch_adonisyee.json  \n",
    "  \n",
    "  inflating: __MACOSX/adonisyee/labels/._stretch_adonisyee.json \n",
    "  \n",
    "  inflating: adonisyee/labels/reach_adonisyee.json  \n",
    "  \n",
    "  inflating: __MACOSX/adonisyee/labels/._reach_adonisyee.json \n",
    "  \n",
    "  inflating: adonisyee/labels/deadbug_adonisyee.json  \n",
    "  inflating: __MACOSX/adonisyee/labels/._deadbug_adonisyee.json\n",
    "  \n",
    "  inflating: adonisyee/labels/export-2019-03-31T02_12_19.175Z.json\n",
    "  \n",
    "  inflating: __MACOSX/adonisyee/labels/._export-2019-03-31T02_12_19.175Z.json\n",
    "  \n",
    "  inflating: adonisyee/labels/pushup_adonisyee.json\n",
    "  \n",
    "  inflating: __MACOSX/adonisyee/labels/._pushup_adonisyee.json\n",
    "  \n",
    "   creating: adonisyee/key_frames/\n",
    "   \n",
    "  inflating: adonisyee/key_frames/hamstring_l.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/.DS_Store\n",
    "  \n",
    "  inflating: adonisyee/key_frames/pushup.jpg\n",
    "  \n",
    "  inflating: __MACOSX/adonisyee/key_frames/._pushup.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/stretch_r.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/lunge_l.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/deadbug_r.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/reach.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/inline_r.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/stretch_l.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/lunge_r.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/deadbug_l.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/inline_l.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/hamstring_r.jpg\n",
    "  \n",
    "  inflating: adonisyee/key_frames/squat.jpg\n",
    "  \n",
    "Checking directory structure of unpacked folder......\n",
    "\n",
    "Passed!\n",
    "\n",
    "Checking key frames......\n",
    "\n",
    "Passed!\n",
    "\n",
    "Checking keypoints label file......\n",
    "\n",
    "Passed!\n",
    "\n",
    "Checking video label files......\n",
    "\n",
    "Checking label file adonisyee/labels/lunge_adonisyee.json\n",
    "\n",
    "Checking label file adonisyee/labels/squat_adonisyee.json\n",
    "\n",
    "Checking label file adonisyee/labels/inline_adonisyee.json\n",
    "\n",
    "Checking label file adonisyee/labels/hamstrings_adonisyee.json\n",
    "\n",
    "Checking label file adonisyee/labels/stretch_adonisyee.json\n",
    "\n",
    "Checking label file adonisyee/labels/reach_adonisyee.json\n",
    "\n",
    "Checking label file adonisyee/labels/deadbug_adonisyee.json\n",
    "\n",
    "Checking label file adonisyee/labels/pushup_adonisyee.json\n",
    "\n",
    "Passed!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the starter code and some suggested architecture we \n",
    "provide you with. But feel free to do any modifications as you\n",
    "wish or just completely ignore all of them and have your own \n",
    "implementations.\n",
    "\"\"\"\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "class DecisionTree():\n",
    "\n",
    "    def __init__(self, X, y, depth, nsize, features):\n",
    "        \"\"\"\n",
    "        TODO: initialization of a decision tree\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.features = features\n",
    "        self.split_rule = self.segmenter(self.X, self.y)\n",
    "        self.depth = depth\n",
    "        self.nsize = nsize\n",
    "        self.left = []\n",
    "        self.right = []\n",
    "        self.label = ''\n",
    "        \n",
    "    @staticmethod\n",
    "    def entropy(y):\n",
    "        \"\"\"\n",
    "        TODO: implement a method that calculates the entropy given all the labels\n",
    "        \"\"\"\n",
    "        return scipy.stats.entropy(np.array(list(Counter(y).values())) / len(y),\n",
    "                                   base=2)\n",
    "\n",
    "    @staticmethod\n",
    "    def information_gain(X, y, thresh):\n",
    "        \"\"\"\n",
    "        TODO: implement a method that calculates information \n",
    "        gain given a vector of features\n",
    "        and a split threshold\n",
    "        \"\"\"\n",
    "        H = DecisionTree.entropy(y)\n",
    "        meet_thresh = X < thresh\n",
    "        S_l = y[meet_thresh]\n",
    "        S_r = y[~meet_thresh]\n",
    "        H_Sl = len(S_l)*DecisionTree.entropy(S_l)\n",
    "        H_Sr = len(S_r)*DecisionTree.entropy(S_r)\n",
    "        H_after = (H_Sl + H_Sr)/len(y)\n",
    "        return H - H_after\n",
    "\n",
    "    @staticmethod\n",
    "    def gini_impurity(y):\n",
    "        \"\"\"\n",
    "        TODO: implement a method that calculates the gini \n",
    "        impurity given all the labels\n",
    "        \"\"\"\n",
    "        probs = np.array(list(Counter(y).values()))/len(y)\n",
    "        return np.sum(probs * (1-probs))\n",
    "\n",
    "    @staticmethod\n",
    "    def gini_purification(X, y, thresh):\n",
    "        \"\"\"\n",
    "        TODO: implement a method that calculates reduction in \n",
    "        impurity gain given a vector of features\n",
    "        and a split threshold\n",
    "        \"\"\"\n",
    "        g = DecisionTree.gini_impurity(y)\n",
    "        meet_thresh = X < thresh\n",
    "        S_l = y[meet_thresh]\n",
    "        S_r = y[~meet_thresh]\n",
    "        g_Sl = len(S_l)*DecisionTree.gini_impurity(S_l)\n",
    "        g_Sr = len(S_r)*DecisionTree.gini_impurity(S_r)\n",
    "        g_after = (g_Sl + g_Sr)/len(y)\n",
    "        return g - g_after\n",
    "\n",
    "    def split(self, X, y, idx, thresh):\n",
    "        \"\"\"\n",
    "        TODO: implement a method that returns a split of the \n",
    "        dataset given an index of the feature and\n",
    "        a threshold for it\n",
    "        \"\"\"\n",
    "        meet_thresh = X[:, idx] < thresh\n",
    "        S_l_X = X[meet_thresh]\n",
    "        S_r_X = X[~meet_thresh]\n",
    "        S_l_y = y[meet_thresh]\n",
    "        S_r_y = y[~meet_thresh]\n",
    "        return S_l_X, S_r_X, S_l_y, S_r_y\n",
    "    \n",
    "    def segmenter(self, X, y):\n",
    "        \"\"\"\n",
    "        TODO: compute entropy gain for all single-dimension splits,\n",
    "        return the feature and the threshold for the split that\n",
    "        has maximum gain\n",
    "        \"\"\"\n",
    "        feat_idxs = np.arange(X.shape[1])\n",
    "        unique_features = [list(Counter(X[:, i]).keys()) for i in feat_idxs]\n",
    "        max_gain = 0\n",
    "        feature = -float('inf')\n",
    "        threshold = -float('inf')\n",
    "        for i in feat_idxs:\n",
    "            for val in unique_features[i]:\n",
    "                #gain = DecisionTree.information_gain(X[:, i], y, val)\n",
    "                gain = DecisionTree.gini_purification(X[:, i], y, val)\n",
    "                if gain >= max_gain:\n",
    "                    max_gain = gain\n",
    "                    feature = i\n",
    "                    threshold = val\n",
    "        return feature, threshold\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        TODO: fit the model to a training set. Think about what would be \n",
    "        your stopping criteria\n",
    "        \"\"\"\n",
    "        if (len(y)<=self.nsize) or (self.depth==0):\n",
    "            self.label = stats.mode(y)[0][0]\n",
    "            return\n",
    "        if max(list(Counter(y).values()))/len(y)<=.05:\n",
    "            self.label = stats.mode(y)[0][0]\n",
    "            return\n",
    "        X_l, X_r, y_l, y_r = self.split(X, y, self.split_rule[0], \n",
    "                                        self.split_rule[1])\n",
    "        if (len(y_l) <= self.nsize) or (len(y_r) <= self.nsize):\n",
    "            self.label = stats.mode(y)[0][0]\n",
    "            return\n",
    "        self.left = DecisionTree(X_l, y_l, self.depth-1, self.nsize, \n",
    "                                 self.features)\n",
    "        self.right = DecisionTree(X_r, y_r, self.depth-1, self.nsize, \n",
    "                                  self.features)   \n",
    "        self.left.fit(X_l, y_l)\n",
    "        self.right.fit(X_r, y_r)\n",
    "        \n",
    "    def predict_row(self, row):\n",
    "            if self.label != '':\n",
    "                return self.label\n",
    "            if row[self.split_rule[0]] < self.split_rule[1]:\n",
    "                next_level = self.left\n",
    "            else:\n",
    "                next_level = self.right\n",
    "            return next_level.predict_row(row)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        TODO: predict the labels for input data \n",
    "        \"\"\" \n",
    "        return np.array([self.predict_row(row) for row in X])\n",
    "\n",
    "#code to print tree adapted from: \n",
    "#https://stackoverflow.com/questions/20242479/printing-a-tree-data-structure-in-python\n",
    "    def __repr__(self, level=0):\n",
    "        \"\"\"\n",
    "        TODO: one way to visualize the decision tree is \n",
    "        to write out a __repr__ method that returns the string \n",
    "        representation of a tree. Think about how to visualize \n",
    "        a tree structure. You might have seen this before in CS61A.\n",
    "        \"\"\"\n",
    "        word = self.features[self.split_rule[0]]\n",
    "        threshold = self.split_rule[1]\n",
    "        ret = \"\\t\"*level+repr(word+' '+str(threshold))+\"\\n\"\n",
    "        if self.label != '':\n",
    "            ret += \"\\t\"*(level+2)+repr(self.label)+\"\\n\"\n",
    "        if self.left != []:\n",
    "            ret += self.left.__repr__(level+1)\n",
    "        if self.right != []:\n",
    "            ret += self.right.__repr__(level+1)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class RandomForest():\n",
    "    def __init__(self, X, y, sample_size, depth, nsize, features):\n",
    "        \"\"\"\n",
    "        TODO: initialization of a random forest\n",
    "        \"\"\"\n",
    "        np.random.seed(42)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.depth = depth\n",
    "        self.nsize = nsize\n",
    "        self.features = features\n",
    "        self.m_features = int(np.sqrt(self.X.shape[1]))\n",
    "        self.sample_size = sample_size\n",
    "        self.trees = [self.make_tree() for i in np.arange(10)]\n",
    "    \n",
    "    def make_tree(self):\n",
    "        indices = np.random.permutation(len(self.y))[:self.sample_size]\n",
    "        feat_indices = np.random.permutation(self.X.shape[1])[:self.m_features]\n",
    "        X_samp = self.X[:, feat_indices]\n",
    "        return DecisionTree(X_samp[indices], self.y[indices], self.depth, \n",
    "                            self.nsize, self.features[feat_indices])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        TODO: fit the model to a training set.\n",
    "        \"\"\"\n",
    "        for t in self.trees:\n",
    "            t.fit(X, y)\n",
    "        return\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        TODO: predict the labels for input data \n",
    "        \"\"\"\n",
    "        return stats.mode([t.predict(X) for t in self.trees], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How did you deal with categorical features and missing values? \n",
    "I dealt with categorical features by using one-hot encoding. I dealt\n",
    "with missing values by inferring them using either a mean or mode of the\n",
    "feature being dealt with after filtering the data based on other features\n",
    "that were similar to the one with the missing value. For example, I used\n",
    "the mean age of people in first class to infer the age of someone in first\n",
    "class with a missing age.\n",
    "\n",
    "2. What was your stopping criterion?\n",
    "My stopping criterion were if I reached a certain depth level found with\n",
    "validation testing, if 95% of the points in the node had the same label,\n",
    "if the size of a node got to be smaller than a number found with \n",
    "validation testing, or if splitting would result in a node smaller\n",
    "than that determined number.\n",
    "\n",
    "3. How did you implement random forests?\n",
    "I implemented random forests by creating multiple decision trees, \n",
    "picking sqrt(len(features)) randomly for each tree and using a \n",
    "sample of data points (size picked with validation) for each tree. \n",
    "Then I trained each tree and made a prediction for each, using the \n",
    "mode of predictions for each point as the final prediction.\n",
    "\n",
    "4. Did you do anything special to speed up training?\n",
    "I made sure to use Counter wherever I could and use masks\n",
    "for comparisons wherever I could in my Decision Tree.\n",
    "Everything ran in no more than a few seconds except\n",
    "for random forests for spam, which still ran in about\n",
    "30 seconds or so.\n",
    "\n",
    "5. Anything else cool you implemented?\n",
    "For titanic, I utilized the cabin feature despite so many\n",
    "nans by filtering the cabins down to the deck letter and\n",
    "assigning deck letters with probabilities depending on \n",
    "which class the person was in. I googled deck levels on\n",
    "the titanic to help figure out which deck levels to assign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(data, split_val):\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(data)\n",
    "    train = data[:split_val]\n",
    "    validation = data[split_val:]\n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_titanic(path, istest):\n",
    "    # Load titanic data       \n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    if not istest:\n",
    "        #drop missing label rows\n",
    "        data = data.drop(data[pd.isnull(data['survived'])].index)\n",
    "\n",
    "    #make sex numerical\n",
    "    data[['female', 'male']] = pd.get_dummies(data['sex'])\n",
    "    data['sex'] = data['male']\n",
    "    data = data.drop(['male', 'female'], axis=1)\n",
    "\n",
    "    #infer missing age using mean age of people in same pclass\n",
    "    mean_3 = np.round(data[data['pclass'] == 3.0]['age'].mean())\n",
    "    mean_2 = np.round(data[data['pclass'] == 2.0]['age'].mean())\n",
    "    mean_1 = np.round(data[data['pclass'] == 1.0]['age'].mean())\n",
    "    age = data.apply(lambda row: mean_3 if np.isnan(row['age']) \n",
    "                      and row['pclass'] == 3.0 else row['age'], axis=1)\n",
    "    data['age'] = age\n",
    "    age = data.apply(lambda row: mean_2 if np.isnan(row['age'])\n",
    "                      and row['pclass'] == 2.0 else row['age'], axis=1)\n",
    "    data['age'] = age\n",
    "    age = data.apply(lambda row: mean_1 if np.isnan(row['age']) \n",
    "                      and row['pclass'] == 1.0 else row['age'], axis=1)\n",
    "    data['age'] = age\n",
    "\n",
    "    #infer missing fare cost using mean cost of tickets with same pclass\n",
    "    mean_fare_3 = np.round(data[data['pclass'] == 3.0]['fare'].mean(), 4)\n",
    "    mean_fare_2 = np.round(data[data['pclass'] == 2.0]['fare'].mean(), 4)\n",
    "    mean_fare_1 = np.round(data[data['pclass'] == 1.0]['fare'].mean(), 4)\n",
    "\n",
    "    fare = data.apply(lambda row: mean_fare_3 if np.isnan(row['fare']) \n",
    "                       and row['pclass'] == 3.0 else row['fare'], axis=1)\n",
    "    data['fare'] = fare\n",
    "    fare = data.apply(lambda row: mean_fare_2 if np.isnan(row['fare']) \n",
    "                       and row['pclass'] == 2.0 else row['fare'], axis=1)\n",
    "    data['fare'] = fare\n",
    "    fare = data.apply(lambda row: mean_fare_1 if np.isnan(row['fare']) \n",
    "                       and row['pclass'] == 1.0 else row['fare'], axis=1)\n",
    "    data['fare'] = fare\n",
    "    \n",
    "    #ticket field is all different, drop it\n",
    "    data = data.drop('ticket', axis=1)\n",
    "    \n",
    "    #infer cabin values based on pclass, then make numerical\n",
    "    np.random.seed(42)\n",
    "    data['cab'] = data.apply(lambda row: np.random.choice(['G', 'F'], \n",
    "                                                          p=[.7, .3]) \n",
    "                             if pd.isnull(row['cabin']) \n",
    "                             and row['pclass']==3.0 \n",
    "                             else row['cabin'], axis=1)\n",
    "    data['cab'] = data.apply(lambda row: np.random.choice(['D', 'E', 'F'], \n",
    "                                                          p=[.2, .6, .2]) \n",
    "                               if pd.isnull(row['cab']) \n",
    "                               and row['pclass']==2.0 \n",
    "                             else row['cab'], axis=1)\n",
    "    data['cab'] = data.apply(lambda row: np.random.choice(['A', \n",
    "                                                           'B', \n",
    "                                                           'C', \n",
    "                                                           'D'], \n",
    "                                                          p=[.3,.3,.3,.1]) \n",
    "                             if pd.isnull(row['cab']) \n",
    "                             and row['pclass']==1.0 \n",
    "                             else row['cab'], axis=1)\n",
    "    \n",
    "    data['cab'] = data.apply(lambda row: 'G' if 'G' in row['cab'] \n",
    "                             else row['cab'], axis=1)\n",
    "    data['cab'] = data.apply(lambda row: 'F' if 'F' in row['cab'] \n",
    "                             else row['cab'], axis=1)\n",
    "    data['cab'] = data.apply(lambda row: 'E' if 'E' in row['cab'] \n",
    "                             else row['cab'], axis=1)\n",
    "    data['cab'] = data.apply(lambda row: 'D' if 'D' in row['cab'] \n",
    "                             else row['cab'], axis=1)\n",
    "    data['cab'] = data.apply(lambda row: 'C' if 'C' in row['cab'] \n",
    "                             else row['cab'], axis=1)\n",
    "    data['cab'] = data.apply(lambda row: 'B' if 'B' in row['cab'] \n",
    "                             else row['cab'], axis=1)\n",
    "    data['cab'] = data.apply(lambda row: 'A' if 'A' in row['cab'] \n",
    "                             else row['cab'], axis=1)\n",
    "    data['cabin'] = data['cab']\n",
    "    data = data.drop('cab', axis=1)\n",
    "    \n",
    "    if not istest:\n",
    "        data[['cabin A', 'cabin B', \n",
    "              'cabin C', 'cabin D', \n",
    "              'cabin E', 'cabin F', \n",
    "              'cabin G']] = pd.get_dummies(data['cabin']).drop('T', axis=1)\n",
    "    else:\n",
    "        data[['cabin A', 'cabin B', 'cabin C', 'cabin D', \n",
    "              'cabin E', 'cabin F', \n",
    "              'cabin G']] = pd.get_dummies(data['cabin'])\n",
    "    data = data.drop('cabin', axis=1)\n",
    "    \n",
    "    #infer missing embarked values with mode of feature, \n",
    "    #then make numerical\n",
    "    data['embarked'] = data['embarked'].fillna(data['embarked'].mode()[0])\n",
    "    data = data.drop('embarked', axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(dataset, depth, nsize, sample_size=0, test=False): \n",
    "    if dataset == \"titanic\":\n",
    "        # Load titanic data       \n",
    "        path_train = 'datasets/titanic/titanic_training.csv'\n",
    "        path_test = 'datasets/titanic/titanic_testing_data.csv'\n",
    "        data = load_and_clean_titanic(path_train, False)\n",
    "        Z = load_and_clean_titanic(path_test, True).values\n",
    "        y = np.array(data['survived'])\n",
    "        X = data.drop('survived', axis=1)\n",
    "        class_names = [\"Died\", \"Survived\"]\n",
    "        features = np.array(X.columns)\n",
    "        X = X.values\n",
    "        \n",
    "        if not test:\n",
    "            X_train, X_val = train_val_split(X, len(X) - 200)\n",
    "            y_train, y_val = train_val_split(y, len(y) - 200)\n",
    "\n",
    "            if sample_size == 0:\n",
    "                model = DecisionTree(X_train, y_train, depth, \n",
    "                                     nsize, features)\n",
    "            else:\n",
    "                model = RandomForest(X_train, y_train, sample_size, \n",
    "                                     depth, nsize, features)\n",
    "        else:\n",
    "            model = DecisionTree(X, y, depth, nsize, features)\n",
    "\n",
    "\n",
    "        # TODO: preprocess titanic dataset\n",
    "        # Notes: \n",
    "        # 1. Some data points are missing their labels\n",
    "        # 2. Some features are not numerical but categorical\n",
    "        # 3. Some values are missing for some features\n",
    "\n",
    "    elif dataset == \"spam\":\n",
    "        features = np.array([\n",
    "            \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \n",
    "            \"prescription\", \"creative\", \"height\", \"featured\", \n",
    "            \"differ\", \"width\", \"other\", \"energy\", \"business\", \n",
    "            \"message\", \"volumes\", \"revision\", \"path\", \"meter\", \n",
    "            \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "            \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \n",
    "            \"parenthesis\", \"square_bracket\", \"ampersand\", \n",
    "            \"shipping\", \"price\", \"pills\", \"windows\", \"online\", \n",
    "            'email'\n",
    "        ])\n",
    "        assert len(features) == 38\n",
    "\n",
    "        # Load spam data\n",
    "        path_train = 'datasets/spam-dataset/spam_data.mat'\n",
    "        data = scipy.io.loadmat(path_train)\n",
    "        X = data['training_data']\n",
    "        y = np.squeeze(data['training_labels'])\n",
    "        Z = data['test_data']\n",
    "        class_names = [\"Ham\", \"Spam\"]\n",
    "        \n",
    "        if not test:\n",
    "            X_train, X_val = train_val_split(X, len(X) - 1000)\n",
    "            y_train, y_val = train_val_split(y, len(y) - 1000)\n",
    "\n",
    "            if sample_size == 0:\n",
    "                model = DecisionTree(X_train, y_train, depth, \n",
    "                                     nsize, features)\n",
    "            else:\n",
    "                model = RandomForest(X_train, y_train, sample_size, \n",
    "                                     depth, nsize, features)\n",
    "        else:\n",
    "            model = RandomForest(X, y, sample_size, depth, \n",
    "                                 nsize, features)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Dataset %s not handled\" % dataset)\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: train decision tree/random forest on different datasets and \n",
    "    perform the tasks in the problem\n",
    "    \"\"\"\n",
    "    if not test:\n",
    "        model.fit(X_train, y_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "        val_pred = model.predict(X_val)\n",
    "        train_acc = (train_pred==y_train).sum()/len(y_train)\n",
    "        val_acc = (val_pred==y_val).sum()/len(y_val)\n",
    "        return train_acc, val_acc, model\n",
    "    else:\n",
    "        model.fit(X, y)\n",
    "        test_pred = model.predict(Z)\n",
    "        return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.861457334611697 0.86\n",
      "0.8434803451581975 0.848\n",
      "0.8688878235858102 0.861\n",
      "0.8267018216682647 0.825\n",
      "0.8722435282837967 0.859\n"
     ]
    }
   ],
   "source": [
    "#spam decision tree testing\n",
    "dataset = \"spam\"\n",
    "spam_train_acc, spam_val_acc, spam_tree = train_data(dataset,15,1,0,False)\n",
    "print(spam_train_acc, spam_val_acc)\n",
    "\n",
    "spam_train_acc2, spam_val_acc2, spam_tree2 = train_data(dataset,10,1,0,False)\n",
    "print(spam_train_acc2, spam_val_acc2)\n",
    "\n",
    "spam_train_acc3, spam_val_acc3, spam_tree3 = train_data(dataset,20,1,0,False)\n",
    "print(spam_train_acc3, spam_val_acc3)\n",
    "\n",
    "spam_train_acc4, spam_val_acc4, spam_tree4 = train_data(dataset,20,15,0,False)\n",
    "print(spam_train_acc4, spam_val_acc4)\n",
    "\n",
    "spam_train_acc5, spam_val_acc5, spam_tree5 = train_data(dataset,30,1,0,False)\n",
    "print(spam_train_acc5, spam_val_acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8734419942473634 0.858\n"
     ]
    }
   ],
   "source": [
    "#spam random forest testing\n",
    "spam_train_acc,spam_val_acc,spam_tree = train_data(dataset,30,1,4171,False)\n",
    "print(spam_train_acc, spam_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8734419942473634 0.858\n"
     ]
    }
   ],
   "source": [
    "spam_train_acc2,spam_val_acc2,spam_tree2 = train_data(dataset,30,1,3000,False)\n",
    "print(spam_train_acc2, spam_val_acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8729626078619367 0.858\n"
     ]
    }
   ],
   "source": [
    "spam_train_acc3,spam_val_acc3,spam_tree3 = train_data(dataset,30,1,2000,False)\n",
    "print(spam_train_acc3, spam_val_acc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8734419942473634 0.856\n"
     ]
    }
   ],
   "source": [
    "spam_train_acc4,spam_val_acc4,spam_tree4 = train_data(dataset,30,1,500,False)\n",
    "print(spam_train_acc4, spam_val_acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8338926174496645 0.831\n"
     ]
    }
   ],
   "source": [
    "spam_train_acc4,spam_val_acc4,spam_tree4 = train_data(dataset,30,10,3000,False)\n",
    "print(spam_train_acc4, spam_val_acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696069031639502 0.86\n"
     ]
    }
   ],
   "source": [
    "spam_train_acc3,spam_val_acc3,spam_tree3 = train_data(dataset,20,1,2000,False)\n",
    "print(spam_train_acc3, spam_val_acc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8147684605757196 0.835\n",
      "0.886107634543179 0.78\n",
      "0.8360450563204005 0.81\n",
      "0.8072590738423029 0.81\n",
      "0.886107634543179 0.78\n"
     ]
    }
   ],
   "source": [
    "#titanic decision tree testing\n",
    "dataset = \"titanic\"\n",
    "t_train_acc, t_val_acc, t_tree = train_data(dataset, 3, 1, 0, False)\n",
    "print(t_train_acc, t_val_acc)\n",
    "t_train_acc2, t_val_acc2, t_tree2 = train_data(dataset, 15, 1, 0, False)\n",
    "print(t_train_acc2, t_val_acc2)\n",
    "t_train_acc3, t_val_acc3, t_tree3 = train_data(dataset, 5, 1, 0, False)\n",
    "print(t_train_acc3, t_val_acc3)\n",
    "t_train_acc4, t_val_acc4, t_tree4 = train_data(dataset, 3, 10, 0, False)\n",
    "print(t_train_acc4, t_val_acc4)\n",
    "t_train_acc5, t_val_acc5, t_tree5 = train_data(dataset, 30, 1, 0, False)\n",
    "print(t_train_acc5, t_val_acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7972465581977471 0.755\n"
     ]
    }
   ],
   "source": [
    "#titanic random forest testing\n",
    "t_train_acc, t_val_acc, t_tree = train_data(dataset, 3, 1, 699, False)\n",
    "print(t_train_acc, t_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8710888610763454 0.8\n"
     ]
    }
   ],
   "source": [
    "t_train_acc, t_val_acc, t_tree = train_data(dataset, 10, 1, 699, False)\n",
    "print(t_train_acc, t_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8748435544430538 0.8\n"
     ]
    }
   ],
   "source": [
    "t_train_acc, t_val_acc, t_tree = train_data(dataset, 20, 1, 699, False)\n",
    "print(t_train_acc, t_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6332916145181476 0.535\n"
     ]
    }
   ],
   "source": [
    "t_train_acc, t_val_acc, t_tree = train_data(dataset, 10, 10, 699, False)\n",
    "print(t_train_acc, t_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660826032540676 0.805\n"
     ]
    }
   ],
   "source": [
    "t_train_acc, t_val_acc, t_tree = train_data(dataset, 10, 1, 300, False)\n",
    "print(t_train_acc, t_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869837296620776 0.79\n"
     ]
    }
   ],
   "source": [
    "t_train_acc, t_val_acc, t_tree = train_data(dataset, 10, 1, 200, False)\n",
    "print(t_train_acc, t_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869837296620776 0.79\n"
     ]
    }
   ],
   "source": [
    "t_train_acc, t_val_acc, t_tree = train_data(dataset, 10, 1, 350, False)\n",
    "print(t_train_acc, t_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_csv(test, submission_name):\n",
    "    test = test.astype(int)\n",
    "    df = pd.DataFrame({'Category': test}, index=np.arange(len(test)))\n",
    "    df.index += 1  # Ensures that the index starts at 1. \n",
    "    df.to_csv(submission_name, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaggle submissions generation\n",
    "spam_test_pred = train_data(\"spam\", 20, 1, 2000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_csv(spam_test_pred[0][0], 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_pred = train_data(\"titanic\", 3, 1, 0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_csv(titanic_test_pred, 'titanic_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies:\n",
    "\n",
    "For the spam dataset, Decision Tree: \n",
    "\n",
    "Training accuracy = 0.8688878235858102\n",
    "\n",
    "Validation accuracy = 0.861\n",
    "\n",
    "\n",
    "For the spam dataset, Random Forest: \n",
    "\n",
    "Training accuracy = 0.8696069031639502\n",
    "\n",
    "Validation accuracy = 0.86\n",
    "\n",
    "\n",
    "For the titanic dataset, Decision Tree:\n",
    "\n",
    "Training accuracy = 0.8147684605757196 \n",
    "\n",
    "Validation accuracy = 0.835\n",
    "\n",
    "\n",
    "For the titanic dataset, Random Forest:\n",
    "\n",
    "Training accuracy = 0.8748435544430538 \n",
    "\n",
    "Validation accuracy = 0.8\n",
    "\n",
    "\n",
    "Kaggle Submissions:\n",
    "\n",
    "username = ayee\n",
    "\n",
    "submission accuracy, spam = 0.78030\n",
    "\n",
    "submission accuracy, titanic = 0.84946"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For spam, I added features for 2 more words I thought were\n",
    "common in spam. I also found the 5 most common words in \n",
    "spam, filtering out words I thought common in spam and ham\n",
    "manually, and used those words as features. \n",
    "\n",
    "1. I added a feature for a word I thought was common in spam (\"shipping\") \n",
    "by using the same type of code that was used for the standard features in\n",
    "featurize.py. Then, I found the 5 most common words in the spam files that\n",
    "were 5 letters or longer while filtering out words I thought would be \n",
    "common in both spam and ham, and I used those words as features. All\n",
    "these features were implemented in featurize.py.\n",
    "\n",
    "\n",
    "2. \n",
    "Splits of a spam email:\n",
    "\n",
    "(a) (\"exclamation\") >= 1\n",
    "\n",
    "(b) (\"ampersand\") < 1\n",
    "\n",
    "(c) (\"meter\") < 1\n",
    "\n",
    "(d) (\"volumes\") < 1\n",
    "\n",
    "(e) (\"money\") < 1\n",
    "\n",
    "(f) (\"dollar\") < 2\n",
    "\n",
    "(g) (\"message\") < 1\n",
    "\n",
    "(h) (\"prescription\") < 1\n",
    "\n",
    "(i) (\"semicolon\") >= 1\n",
    "\n",
    "(j) (\"other\") < 1\n",
    "\n",
    "(k) (\"parenthesis\") < 1\n",
    "\n",
    "(l) (\"exclamation\") < 2\n",
    "\n",
    "(m) Therefore the email was classified as spam\n",
    "\n",
    "Splits of a ham email:\n",
    "\n",
    "(a) ('exclamation') < 1\n",
    "\n",
    "(b) ('meter') < 1\n",
    "\n",
    "(c) ('online') < 1\n",
    "\n",
    "(d) ('parenthesis') >= 1\n",
    "\n",
    "(e) ('private') < 1\n",
    "\n",
    "(f) ('differ') < 1\n",
    "\n",
    "(g) ('pills') < 1\n",
    "\n",
    "(h) ('dollar') < 2\n",
    "\n",
    "(i) ('windows') < 2\n",
    "\n",
    "(j) ('money') < 1\n",
    "\n",
    "(k) Therefore the message was classified as ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 1.0\n",
      ">=\n",
      "31 1.0\n",
      "<\n",
      "19 1.0\n",
      "<\n",
      "16 1.0\n",
      "<\n",
      "3 1.0\n",
      "<\n",
      "26 2.0\n",
      "<\n",
      "15 1.0\n",
      "<\n",
      "6 1.0\n",
      "<\n",
      "25 1.0\n",
      ">=\n",
      "12 1.0\n",
      "<\n",
      "29 1.0\n",
      "<\n",
      "28 2.0\n",
      "<\n",
      "1\n",
      "28 1.0\n",
      "<\n",
      "19 1.0\n",
      "<\n",
      "36 1.0\n",
      "<\n",
      "29 1.0\n",
      ">=\n",
      "1 1.0\n",
      "<\n",
      "10 1.0\n",
      "<\n",
      "34 1.0\n",
      "<\n",
      "26 2.0\n",
      "<\n",
      "35 2.0\n",
      "<\n",
      "3 1.0\n",
      "<\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 1261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I inserted print statements into the tree to find \n",
    "#these splits, they are no longer there\n",
    "spam_tree3.predict([X[0], X[len(y)-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_val(dataset, depth, nsize): \n",
    "    if dataset == \"spam\":\n",
    "        features = np.array([\n",
    "            \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \n",
    "            \"prescription\", \"creative\", \"height\", \"featured\", \n",
    "            \"differ\", \"width\", \"other\", \"energy\", \"business\", \n",
    "            \"message\", \"volumes\", \"revision\", \"path\", \"meter\", \n",
    "            \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "            \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \n",
    "            \"parenthesis\", \"square_bracket\", \"ampersand\", \n",
    "            \"shipping\", \"price\", \"pills\", \"windows\", \"online\", \n",
    "            'email'\n",
    "        ])\n",
    "        assert len(features) == 38\n",
    "\n",
    "        # Load spam data\n",
    "        path_train = 'datasets/spam-dataset/spam_data.mat'\n",
    "        data = scipy.io.loadmat(path_train)\n",
    "        X = data['training_data']\n",
    "        y = np.squeeze(data['training_labels'])\n",
    "        class_names = [\"Ham\", \"Spam\"]\n",
    "\n",
    "        X_train, X_val = train_val_split(X, int(np.round(len(X)*.8)))\n",
    "        y_train, y_val = train_val_split(y, int(np.round(len(y)*.8)))\n",
    "            \n",
    "        model = DecisionTree(X_train, y_train, depth, \n",
    "                                     nsize, features)  \n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Dataset %s not handled\" % dataset)\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: train decision tree/random forest on different datasets and \n",
    "    perform the tasks in the problem\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_acc = (val_pred==y_val).sum()/len(y_val)\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracies = np.array([])\n",
    "for i in np.arange(40):\n",
    "    val_acc = train_data_val('spam', i+1, 1)\n",
    "    val_accuracies = np.append(val_accuracies, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(np.arange(1,41), val_accuracies)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracies for Depth 1-40');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The depth with the highest validation accuracy was 15. We see that as depth\n",
    "increases the accuracy increases as the model gets better, but after depth 15\n",
    "the model begins to overfit and the validation accuracy decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([15]),)"
      ]
     },
     "execution_count": 1313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(val_accuracies==max(val_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\pagebreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sex 1.0'\n",
       "\t'pclass 3.0'\n",
       "\t\t'fare 26.25'\n",
       "\t\t\t'age 60.0'\n",
       "\t\t\t\t\t1.0\n",
       "\t\t\t'age 3.0'\n",
       "\t\t\t\t\t1.0\n",
       "\t\t'fare 23.45'\n",
       "\t\t\t'age 26.0'\n",
       "\t\t\t\t\t1.0\n",
       "\t\t\t'age 10.0'\n",
       "\t\t\t\t\t0.0\n",
       "\t'age 11.5'\n",
       "\t\t'sibsp 4.0'\n",
       "\t\t\t'fare 15.9'\n",
       "\t\t\t\t\t1.0\n",
       "\t\t\t'cabin G 1.0'\n",
       "\t\t\t\t\t0.0\n",
       "\t\t'pclass 2.0'\n",
       "\t\t\t'age 55.0'\n",
       "\t\t\t\t\t0.0\n",
       "\t\t\t'age 33.0'\n",
       "\t\t\t\t\t0.0"
      ]
     },
     "execution_count": 1328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"titanic\"\n",
    "t_train_acc, t_val_acc, t_tree = train_data(dataset, 3, 1, 0, False)\n",
    "t_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the leaf nodes, 0 = Died and 1 = Survived. I did not feel like modifying everything\n",
    "to keep track of the class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
